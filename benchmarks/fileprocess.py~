import string

def file_to_words(filename):
    """Read a file and return a sequence of (word, occurances) values.
    """
    STOP_WORDS = set([
            'a', 'an', 'and', 'are', 'as', 'be', 'by', 'for', 'if', 'in', 
            'is', 'it', 'of', 'or', 'py', 'rst', 'that', 'the', 'to', 'with',
            ])
    TR = string.maketrans(string.punctuation, ' ' * len(string.punctuation))

    #print multiprocessing.current_process().name, 'reading', filename
    output = []

    dic = {}
    with open(filename, 'rt') as f:
        for line in f:
            if line.lstrip().startswith('..'): # Skip rst comment lines
                continue
            line = line.translate(TR) # Strip punctuation
            for word in line.split():
                word = word.lower()
                if word.isalpha() and word not in STOP_WORDS:
		    if word in dic:
                    	dic[word] += 1
		    else:
			dic[word] = 0
    return dic

if __name__ == '__main__':
    MAX = 3
    import operator
    import glob

    input_files = glob.glob('testdata/*.rst')
    address = ('localhost', 6000)
    listener = Listener(address, authkey='secret password')
    scale = MAX
    connections = []
    while True:
	if scale:
		scale -= 1
		conn = listener.accept()
		connections.append(conn)
	    	print 'connection accepted from', listener.last_accepted
	else:
		break

    now = time.time()
    next = MAX-1
    for _file in input_files:
    	connections[next].send(_file)
	next -= 1
	if next < 0:
		break

    for conn in connections:
	x = conn.recv()
	print x
	conn.close()

    listener.close()
    dist = time.time() - now
    now = time.time()
    _list = []
    for _file in input_files:
	p = file_to_words(_file)
	_list.append(p)
	print p
    seq = time.time() - now
    total = sum([len(x) for x in _list])
    print total
    print "Distributed time : ",
    print dist
    print "sequential time : ",
    print seq
